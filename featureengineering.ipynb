{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "The goals of this course are to:\n",
    "\n",
    "-   Understand the importance of feature engineering\n",
    "-   Learn how to create new features from existing data\n",
    "-   Learn how to use domain knowledge to create new features\n",
    "-   Learn how to encode categorical variables for machine learning\n",
    "-   Learn how to handle missing values in a dataset\n",
    "-   Learn how to deal with time series data\n",
    "-   Learn how to scale features for machine learning\n",
    "-   Learn how to evaluate features\n",
    "-   Learn how to use Pandas and Scikit-Learn to engineer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation\n",
    "\n",
    "*Imputation* means to fill in missing values with plausible values. There are many\n",
    "options:\n",
    "\n",
    "-  A constant value that has meaning within the domain, such as 0, distinct from all\n",
    "    other values.\n",
    "-  A value from another randomly selected record.\n",
    "-  A mean, median or mode value for the column.\n",
    "-  A value estimated by another predictive model.\n",
    "\n",
    "We use imputation because many machine learning algorithms do not support missing values. Modern algorithms like XGBoost handle missing values themselves, but it is still a common practice to impute because other algorithms do not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Fuel economy data from the U.S. Environmental Protection Agency (EPA) for 2019 model year vehicles. The data are available in a CSV file with 82,000 rows and 83 columns.\n",
    "\n",
    "https://www.fueleconomy.gov/feg/epadata/vehicles.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (16.1.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pyarrow) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import certifi\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6w/k13p0nq95dggbfm0scx2d38r0000gn/T/ipykernel_134/794973991.py:4: DtypeWarning: Columns (72,74,75,77) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw = pd.read_csv(url)#, dtype_backend='pyarrow', engine='pyarrow')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://www.fueleconomy.gov/feg/epadata/vehicles.csv' \n",
    "\n",
    "raw = pd.read_csv(url)#, dtype_backend='pyarrow', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barrels08</th>\n",
       "      <th>barrelsA08</th>\n",
       "      <th>charge120</th>\n",
       "      <th>charge240</th>\n",
       "      <th>city08</th>\n",
       "      <th>city08U</th>\n",
       "      <th>cityA08</th>\n",
       "      <th>cityA08U</th>\n",
       "      <th>cityCD</th>\n",
       "      <th>cityE</th>\n",
       "      <th>...</th>\n",
       "      <th>mfrCode</th>\n",
       "      <th>c240Dscr</th>\n",
       "      <th>charge240b</th>\n",
       "      <th>c240bDscr</th>\n",
       "      <th>createdOn</th>\n",
       "      <th>modifiedOn</th>\n",
       "      <th>startStop</th>\n",
       "      <th>phevCity</th>\n",
       "      <th>phevHwy</th>\n",
       "      <th>phevComb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.167143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.046364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.018889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.046364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.658421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47518</th>\n",
       "      <td>13.523182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47519</th>\n",
       "      <td>12.935217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47520</th>\n",
       "      <td>14.167143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47521</th>\n",
       "      <td>14.167143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47522</th>\n",
       "      <td>16.528333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47523 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       barrels08  barrelsA08  charge120  charge240  city08  city08U  cityA08  \\\n",
       "0      14.167143         0.0        0.0        0.0      19      0.0        0   \n",
       "1      27.046364         0.0        0.0        0.0       9      0.0        0   \n",
       "2      11.018889         0.0        0.0        0.0      23      0.0        0   \n",
       "3      27.046364         0.0        0.0        0.0      10      0.0        0   \n",
       "4      15.658421         0.0        0.0        0.0      17      0.0        0   \n",
       "...          ...         ...        ...        ...     ...      ...      ...   \n",
       "47518  13.523182         0.0        0.0        0.0      19      0.0        0   \n",
       "47519  12.935217         0.0        0.0        0.0      20      0.0        0   \n",
       "47520  14.167143         0.0        0.0        0.0      18      0.0        0   \n",
       "47521  14.167143         0.0        0.0        0.0      18      0.0        0   \n",
       "47522  16.528333         0.0        0.0        0.0      16      0.0        0   \n",
       "\n",
       "       cityA08U  cityCD  cityE  ...  mfrCode  c240Dscr  charge240b  c240bDscr  \\\n",
       "0           0.0     0.0    0.0  ...      NaN       NaN         0.0        NaN   \n",
       "1           0.0     0.0    0.0  ...      NaN       NaN         0.0        NaN   \n",
       "2           0.0     0.0    0.0  ...      NaN       NaN         0.0        NaN   \n",
       "3           0.0     0.0    0.0  ...      NaN       NaN         0.0        NaN   \n",
       "4           0.0     0.0    0.0  ...      NaN       NaN         0.0        NaN   \n",
       "...         ...     ...    ...  ...      ...       ...         ...        ...   \n",
       "47518       0.0     0.0    0.0  ...      NaN       NaN         0.0        NaN   \n",
       "47519       0.0     0.0    0.0  ...      NaN       NaN         0.0        NaN   \n",
       "47520       0.0     0.0    0.0  ...      NaN       NaN         0.0        NaN   \n",
       "47521       0.0     0.0    0.0  ...      NaN       NaN         0.0        NaN   \n",
       "47522       0.0     0.0    0.0  ...      NaN       NaN         0.0        NaN   \n",
       "\n",
       "                          createdOn                    modifiedOn  startStop  \\\n",
       "0      Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013        NaN   \n",
       "1      Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013        NaN   \n",
       "2      Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013        NaN   \n",
       "3      Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013        NaN   \n",
       "4      Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013        NaN   \n",
       "...                             ...                           ...        ...   \n",
       "47518  Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013        NaN   \n",
       "47519  Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013        NaN   \n",
       "47520  Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013        NaN   \n",
       "47521  Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013        NaN   \n",
       "47522  Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013        NaN   \n",
       "\n",
       "       phevCity  phevHwy  phevComb  \n",
       "0             0        0         0  \n",
       "1             0        0         0  \n",
       "2             0        0         0  \n",
       "3             0        0         0  \n",
       "4             0        0         0  \n",
       "...         ...      ...       ...  \n",
       "47518         0        0         0  \n",
       "47519         0        0         0  \n",
       "47520         0        0         0  \n",
       "47521         0        0         0  \n",
       "47522         0        0         0  \n",
       "\n",
       "[47523 rows x 84 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['barrels08', 'barrelsA08', 'charge120', 'charge240', 'city08',\n",
       "       'city08U', 'cityA08', 'cityA08U', 'cityCD', 'cityE', 'cityUF', 'co2',\n",
       "       'co2A', 'co2TailpipeAGpm', 'co2TailpipeGpm', 'comb08', 'comb08U',\n",
       "       'combA08', 'combA08U', 'combE', 'combinedCD', 'combinedUF', 'cylinders',\n",
       "       'displ', 'drive', 'engId', 'eng_dscr', 'feScore', 'fuelCost08',\n",
       "       'fuelCostA08', 'fuelType', 'fuelType1', 'ghgScore', 'ghgScoreA',\n",
       "       'highway08', 'highway08U', 'highwayA08', 'highwayA08U', 'highwayCD',\n",
       "       'highwayE', 'highwayUF', 'hlv', 'hpv', 'id', 'lv2', 'lv4', 'make',\n",
       "       'model', 'mpgData', 'phevBlended', 'pv2', 'pv4', 'range', 'rangeCity',\n",
       "       'rangeCityA', 'rangeHwy', 'rangeHwyA', 'trany', 'UCity', 'UCityA',\n",
       "       'UHighway', 'UHighwayA', 'VClass', 'year', 'youSaveSpend', 'baseModel',\n",
       "       'guzzler', 'trans_dscr', 'tCharger', 'sCharger', 'atvType', 'fuelType2',\n",
       "       'rangeA', 'evMotor', 'mfrCode', 'c240Dscr', 'charge240b', 'c240bDscr',\n",
       "       'createdOn', 'modifiedOn', 'startStop', 'phevCity', 'phevHwy',\n",
       "       'phevComb'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year                                     int64\n",
       "make                                    object\n",
       "model                                   object\n",
       "trany                                   object\n",
       "drive                                   object\n",
       "VClass                                  object\n",
       "eng_dscr                                object\n",
       "barrels08                              float64\n",
       "city08                                   int64\n",
       "comb08                                   int64\n",
       "range                                    int64\n",
       "evMotor                                 object\n",
       "cylinders                              float64\n",
       "displ                                  float64\n",
       "fuelCost08                               int64\n",
       "fuelType                                object\n",
       "highway08                                int64\n",
       "trans_dscr                              object\n",
       "createdOn     datetime64[ns, America/New_York]\n",
       "offset                                  object\n",
       "str_date                                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['year', 'make', 'model', 'trany', 'drive', 'VClass', 'eng_dscr',\n",
    "    'barrels08', 'city08', 'comb08', 'range', 'evMotor', 'cylinders', 'displ', 'fuelCost08', \n",
    "        'fuelType', 'highway08',  'trans_dscr','createdOn']\n",
    "\n",
    "def to_tz(df_, time_col, tz_offset, tz_name):\n",
    "    return (df_\n",
    "            .groupby(tz_offset)\n",
    "            [time_col]\n",
    "            .transform(lambda s: pd.to_datetime(s)\n",
    "                       .dt.tz_localize(s.name, ambiguous=True)\n",
    "                       .dt.tz_convert(tz_name))\n",
    "            )\n",
    "\n",
    "autos = (raw.loc[:, cols]\n",
    "         .assign(\n",
    "            offset=(raw.createdOn.str.extract(r'\\d\\d:\\d\\d (?P<offset>[A-Z]{3}?)')\n",
    "                .replace('EDT', 'EST5EDT')),\n",
    "            str_date=(raw.createdOn.str.slice(4,19) + ' ' +\n",
    "                raw.createdOn.str.slice(-4)),\n",
    "            createdOn=lambda df_: to_tz(df_, 'str_date', 'offset', 'America/New_York')\n",
    "         )\n",
    ")\n",
    "autos.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key insight in Python\n",
    "# booleans are integers\n",
    "\n",
    "True + 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False + 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year           0.0\n",
       "make           0.0\n",
       "model          0.0\n",
       "trany          0.0\n",
       "drive          2.5\n",
       "VClass         0.0\n",
       "eng_dscr      36.7\n",
       "barrels08      0.0\n",
       "city08         0.0\n",
       "comb08         0.0\n",
       "range          0.0\n",
       "evMotor       94.9\n",
       "cylinders      1.7\n",
       "displ          1.7\n",
       "fuelCost08     0.0\n",
       "fuelType       0.0\n",
       "highway08      0.0\n",
       "trans_dscr    68.3\n",
       "createdOn      0.0\n",
       "offset         0.0\n",
       "str_date       0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determining missing values\n",
    "(autos\n",
    " .isna()\n",
    " #.sum()\n",
    " .mean().mul(100).round(1)\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drive          1186\n",
       "eng_dscr      17442\n",
       "fuelType          0\n",
       "fuelType1         0\n",
       "make              0\n",
       "model             0\n",
       "mpgData          41\n",
       "trany            11\n",
       "VClass            0\n",
       "baseModel         0\n",
       "guzzler       44760\n",
       "trans_dscr    32479\n",
       "tCharger      37188\n",
       "sCharger      46517\n",
       "atvType       42202\n",
       "fuelType2     45627\n",
       "rangeA        45632\n",
       "evMotor       45086\n",
       "mfrCode       30808\n",
       "c240Dscr      47382\n",
       "c240bDscr     47388\n",
       "createdOn         0\n",
       "modifiedOn        0\n",
       "startStop     31689\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(raw\n",
    " #.select_dtypes('string[pyarrow]')\n",
    " .select_dtypes(object)\n",
    " .isna()\n",
    " .sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in Missing Values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>trany</th>\n",
       "      <th>drive</th>\n",
       "      <th>VClass</th>\n",
       "      <th>eng_dscr</th>\n",
       "      <th>barrels08</th>\n",
       "      <th>city08</th>\n",
       "      <th>comb08</th>\n",
       "      <th>...</th>\n",
       "      <th>evMotor</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displ</th>\n",
       "      <th>fuelCost08</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>highway08</th>\n",
       "      <th>trans_dscr</th>\n",
       "      <th>createdOn</th>\n",
       "      <th>offset</th>\n",
       "      <th>str_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7138</th>\n",
       "      <td>2000</td>\n",
       "      <td>Nissan</td>\n",
       "      <td>Altra EV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Midsize Station Wagons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0960</td>\n",
       "      <td>81</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>62 KW AC Induction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7139</th>\n",
       "      <td>2000</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>RAV4 EV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2-Wheel Drive</td>\n",
       "      <td>Sport Utility Vehicle - 2WD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1128</td>\n",
       "      <td>81</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>50 KW DC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1050</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8143</th>\n",
       "      <td>2001</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>RAV4 EV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2-Wheel Drive</td>\n",
       "      <td>Sport Utility Vehicle - 2WD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1128</td>\n",
       "      <td>81</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>50 KW DC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1050</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8144</th>\n",
       "      <td>2001</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Th!nk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two Seaters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>74</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>27 KW AC Induction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1150</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8146</th>\n",
       "      <td>2001</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Explorer USPS Electric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2-Wheel Drive</td>\n",
       "      <td>Sport Utility Vehicle - 2WD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2088</td>\n",
       "      <td>45</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>67 KW AC Induction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41693</th>\n",
       "      <td>2024</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>bZ4X AWD</td>\n",
       "      <td>Automatic (A1)</td>\n",
       "      <td>All-Wheel Drive</td>\n",
       "      <td>Small Sport Utility Vehicle 4WD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>114</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>80 and 80 kW AC Synchronous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>700</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-02 00:00:00-04:00</td>\n",
       "      <td>EST5EDT</td>\n",
       "      <td>May 02 00:00:00 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41694</th>\n",
       "      <td>2024</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>bZ4X Limited AWD</td>\n",
       "      <td>Automatic (A1)</td>\n",
       "      <td>All-Wheel Drive</td>\n",
       "      <td>Small Sport Utility Vehicle 4WD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>112</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>80 and 80 kW AC Synchronous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>700</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-02 00:00:00-04:00</td>\n",
       "      <td>EST5EDT</td>\n",
       "      <td>May 02 00:00:00 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41695</th>\n",
       "      <td>2024</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>ID.4</td>\n",
       "      <td>Automatic (A1)</td>\n",
       "      <td>Rear-Wheel Drive</td>\n",
       "      <td>Small Sport Utility Vehicle 2WD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>115</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>210 kW AC 3-Phase</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>700</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-02 00:00:00-04:00</td>\n",
       "      <td>EST5EDT</td>\n",
       "      <td>May 02 00:00:00 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41696</th>\n",
       "      <td>2024</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>ID.4 Pro S</td>\n",
       "      <td>Automatic (A1)</td>\n",
       "      <td>Rear-Wheel Drive</td>\n",
       "      <td>Small Sport Utility Vehicle 2WD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0720</td>\n",
       "      <td>122</td>\n",
       "      <td>113</td>\n",
       "      <td>...</td>\n",
       "      <td>210 kW AC 3-Phase</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>650</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-02 00:00:00-04:00</td>\n",
       "      <td>EST5EDT</td>\n",
       "      <td>May 02 00:00:00 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697</th>\n",
       "      <td>2024</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>ID.4 S</td>\n",
       "      <td>Automatic (A1)</td>\n",
       "      <td>Rear-Wheel Drive</td>\n",
       "      <td>Small Sport Utility Vehicle 2WD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>115</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>210 kW AC 3-Phase</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>700</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-05-02 00:00:00-04:00</td>\n",
       "      <td>EST5EDT</td>\n",
       "      <td>May 02 00:00:00 2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year        make                   model           trany  \\\n",
       "7138   2000      Nissan                Altra EV             NaN   \n",
       "7139   2000      Toyota                 RAV4 EV             NaN   \n",
       "8143   2001      Toyota                 RAV4 EV             NaN   \n",
       "8144   2001        Ford                   Th!nk             NaN   \n",
       "8146   2001        Ford  Explorer USPS Electric             NaN   \n",
       "...     ...         ...                     ...             ...   \n",
       "41693  2024      Toyota                bZ4X AWD  Automatic (A1)   \n",
       "41694  2024      Toyota        bZ4X Limited AWD  Automatic (A1)   \n",
       "41695  2024  Volkswagen                    ID.4  Automatic (A1)   \n",
       "41696  2024  Volkswagen              ID.4 Pro S  Automatic (A1)   \n",
       "41697  2024  Volkswagen                  ID.4 S  Automatic (A1)   \n",
       "\n",
       "                  drive                           VClass eng_dscr  barrels08  \\\n",
       "7138                NaN           Midsize Station Wagons      NaN     0.0960   \n",
       "7139      2-Wheel Drive      Sport Utility Vehicle - 2WD      NaN     0.1128   \n",
       "8143      2-Wheel Drive      Sport Utility Vehicle - 2WD      NaN     0.1128   \n",
       "8144                NaN                      Two Seaters      NaN     0.1248   \n",
       "8146      2-Wheel Drive      Sport Utility Vehicle - 2WD      NaN     0.2088   \n",
       "...                 ...                              ...      ...        ...   \n",
       "41693   All-Wheel Drive  Small Sport Utility Vehicle 4WD      NaN     0.0744   \n",
       "41694   All-Wheel Drive  Small Sport Utility Vehicle 4WD      NaN     0.0768   \n",
       "41695  Rear-Wheel Drive  Small Sport Utility Vehicle 2WD      NaN     0.0768   \n",
       "41696  Rear-Wheel Drive  Small Sport Utility Vehicle 2WD      NaN     0.0720   \n",
       "41697  Rear-Wheel Drive  Small Sport Utility Vehicle 2WD      NaN     0.0768   \n",
       "\n",
       "       city08  comb08  ...                      evMotor cylinders  displ  \\\n",
       "7138       81      85  ...           62 KW AC Induction       NaN    NaN   \n",
       "7139       81      72  ...                     50 KW DC       NaN    NaN   \n",
       "8143       81      72  ...                     50 KW DC       NaN    NaN   \n",
       "8144       74      65  ...           27 KW AC Induction       NaN    NaN   \n",
       "8146       45      39  ...           67 KW AC Induction       NaN    NaN   \n",
       "...       ...     ...  ...                          ...       ...    ...   \n",
       "41693     114     104  ...  80 and 80 kW AC Synchronous       NaN    NaN   \n",
       "41694     112     102  ...  80 and 80 kW AC Synchronous       NaN    NaN   \n",
       "41695     115     107  ...            210 kW AC 3-Phase       NaN    NaN   \n",
       "41696     122     113  ...            210 kW AC 3-Phase       NaN    NaN   \n",
       "41697     115     107  ...            210 kW AC 3-Phase       NaN    NaN   \n",
       "\n",
       "       fuelCost08     fuelType highway08  trans_dscr  \\\n",
       "7138          900  Electricity        91         NaN   \n",
       "7139         1050  Electricity        64         NaN   \n",
       "8143         1050  Electricity        64         NaN   \n",
       "8144         1150  Electricity        58         NaN   \n",
       "8146         1950  Electricity        33         NaN   \n",
       "...           ...          ...       ...         ...   \n",
       "41693         700  Electricity        94         NaN   \n",
       "41694         700  Electricity        92         NaN   \n",
       "41695         700  Electricity        98         NaN   \n",
       "41696         650  Electricity       104         NaN   \n",
       "41697         700  Electricity        98         NaN   \n",
       "\n",
       "                      createdOn   offset              str_date  \n",
       "7138  2013-01-01 00:00:00-05:00      EST  Jan 01 00:00:00 2013  \n",
       "7139  2013-01-01 00:00:00-05:00      EST  Jan 01 00:00:00 2013  \n",
       "8143  2013-01-01 00:00:00-05:00      EST  Jan 01 00:00:00 2013  \n",
       "8144  2013-01-01 00:00:00-05:00      EST  Jan 01 00:00:00 2013  \n",
       "8146  2013-01-01 00:00:00-05:00      EST  Jan 01 00:00:00 2013  \n",
       "...                         ...      ...                   ...  \n",
       "41693 2024-05-02 00:00:00-04:00  EST5EDT  May 02 00:00:00 2024  \n",
       "41694 2024-05-02 00:00:00-04:00  EST5EDT  May 02 00:00:00 2024  \n",
       "41695 2024-05-02 00:00:00-04:00  EST5EDT  May 02 00:00:00 2024  \n",
       "41696 2024-05-02 00:00:00-04:00  EST5EDT  May 02 00:00:00 2024  \n",
       "41697 2024-05-02 00:00:00-04:00  EST5EDT  May 02 00:00:00 2024  \n",
       "\n",
       "[801 rows x 21 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where are cylinders missing?\n",
    "\n",
    "(autos\n",
    " .query('cylinders.isna()')\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>trany</th>\n",
       "      <th>drive</th>\n",
       "      <th>VClass</th>\n",
       "      <th>eng_dscr</th>\n",
       "      <th>barrels08</th>\n",
       "      <th>city08</th>\n",
       "      <th>comb08</th>\n",
       "      <th>...</th>\n",
       "      <th>evMotor</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displ</th>\n",
       "      <th>fuelCost08</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>highway08</th>\n",
       "      <th>trans_dscr</th>\n",
       "      <th>createdOn</th>\n",
       "      <th>offset</th>\n",
       "      <th>str_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>Spider Veloce 2000</td>\n",
       "      <td>Manual 5-spd</td>\n",
       "      <td>Rear-Wheel Drive</td>\n",
       "      <td>Two Seaters</td>\n",
       "      <td>(FFS)</td>\n",
       "      <td>14.167143</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2550</td>\n",
       "      <td>Regular</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985</td>\n",
       "      <td>Ferrari</td>\n",
       "      <td>Testarossa</td>\n",
       "      <td>Manual 5-spd</td>\n",
       "      <td>Rear-Wheel Drive</td>\n",
       "      <td>Two Seaters</td>\n",
       "      <td>(GUZZLER)</td>\n",
       "      <td>27.046364</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4900</td>\n",
       "      <td>Regular</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>Charger</td>\n",
       "      <td>Manual 5-spd</td>\n",
       "      <td>Front-Wheel Drive</td>\n",
       "      <td>Subcompact Cars</td>\n",
       "      <td>(FFS)</td>\n",
       "      <td>11.018889</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2000</td>\n",
       "      <td>Regular</td>\n",
       "      <td>33</td>\n",
       "      <td>SIL</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1985</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>B150/B250 Wagon 2WD</td>\n",
       "      <td>Automatic 3-spd</td>\n",
       "      <td>Rear-Wheel Drive</td>\n",
       "      <td>Vans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.046364</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4900</td>\n",
       "      <td>Regular</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993</td>\n",
       "      <td>Subaru</td>\n",
       "      <td>Legacy AWD Turbo</td>\n",
       "      <td>Manual 5-spd</td>\n",
       "      <td>4-Wheel or All-Wheel Drive</td>\n",
       "      <td>Compact Cars</td>\n",
       "      <td>(FFS,TRBO)</td>\n",
       "      <td>15.658421</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3550</td>\n",
       "      <td>Premium</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47518</th>\n",
       "      <td>1993</td>\n",
       "      <td>Subaru</td>\n",
       "      <td>Legacy</td>\n",
       "      <td>Automatic 4-spd</td>\n",
       "      <td>Front-Wheel Drive</td>\n",
       "      <td>Compact Cars</td>\n",
       "      <td>(FFS)</td>\n",
       "      <td>13.523182</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2450</td>\n",
       "      <td>Regular</td>\n",
       "      <td>26</td>\n",
       "      <td>CLKUP</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47519</th>\n",
       "      <td>1993</td>\n",
       "      <td>Subaru</td>\n",
       "      <td>Legacy</td>\n",
       "      <td>Manual 5-spd</td>\n",
       "      <td>Front-Wheel Drive</td>\n",
       "      <td>Compact Cars</td>\n",
       "      <td>(FFS)</td>\n",
       "      <td>12.935217</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2350</td>\n",
       "      <td>Regular</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47520</th>\n",
       "      <td>1993</td>\n",
       "      <td>Subaru</td>\n",
       "      <td>Legacy AWD</td>\n",
       "      <td>Automatic 4-spd</td>\n",
       "      <td>4-Wheel or All-Wheel Drive</td>\n",
       "      <td>Compact Cars</td>\n",
       "      <td>(FFS)</td>\n",
       "      <td>14.167143</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2550</td>\n",
       "      <td>Regular</td>\n",
       "      <td>24</td>\n",
       "      <td>CLKUP</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47521</th>\n",
       "      <td>1993</td>\n",
       "      <td>Subaru</td>\n",
       "      <td>Legacy AWD</td>\n",
       "      <td>Manual 5-spd</td>\n",
       "      <td>4-Wheel or All-Wheel Drive</td>\n",
       "      <td>Compact Cars</td>\n",
       "      <td>(FFS)</td>\n",
       "      <td>14.167143</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2550</td>\n",
       "      <td>Regular</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47522</th>\n",
       "      <td>1993</td>\n",
       "      <td>Subaru</td>\n",
       "      <td>Legacy AWD Turbo</td>\n",
       "      <td>Automatic 4-spd</td>\n",
       "      <td>4-Wheel or All-Wheel Drive</td>\n",
       "      <td>Compact Cars</td>\n",
       "      <td>(FFS,TRBO)</td>\n",
       "      <td>16.528333</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3750</td>\n",
       "      <td>Premium</td>\n",
       "      <td>21</td>\n",
       "      <td>CLKUP</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47523 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year        make                model            trany  \\\n",
       "0      1985  Alfa Romeo   Spider Veloce 2000     Manual 5-spd   \n",
       "1      1985     Ferrari           Testarossa     Manual 5-spd   \n",
       "2      1985       Dodge              Charger     Manual 5-spd   \n",
       "3      1985       Dodge  B150/B250 Wagon 2WD  Automatic 3-spd   \n",
       "4      1993      Subaru     Legacy AWD Turbo     Manual 5-spd   \n",
       "...     ...         ...                  ...              ...   \n",
       "47518  1993      Subaru               Legacy  Automatic 4-spd   \n",
       "47519  1993      Subaru               Legacy     Manual 5-spd   \n",
       "47520  1993      Subaru           Legacy AWD  Automatic 4-spd   \n",
       "47521  1993      Subaru           Legacy AWD     Manual 5-spd   \n",
       "47522  1993      Subaru     Legacy AWD Turbo  Automatic 4-spd   \n",
       "\n",
       "                            drive           VClass    eng_dscr  barrels08  \\\n",
       "0                Rear-Wheel Drive      Two Seaters       (FFS)  14.167143   \n",
       "1                Rear-Wheel Drive      Two Seaters   (GUZZLER)  27.046364   \n",
       "2               Front-Wheel Drive  Subcompact Cars       (FFS)  11.018889   \n",
       "3                Rear-Wheel Drive             Vans         NaN  27.046364   \n",
       "4      4-Wheel or All-Wheel Drive     Compact Cars  (FFS,TRBO)  15.658421   \n",
       "...                           ...              ...         ...        ...   \n",
       "47518           Front-Wheel Drive     Compact Cars       (FFS)  13.523182   \n",
       "47519           Front-Wheel Drive     Compact Cars       (FFS)  12.935217   \n",
       "47520  4-Wheel or All-Wheel Drive     Compact Cars       (FFS)  14.167143   \n",
       "47521  4-Wheel or All-Wheel Drive     Compact Cars       (FFS)  14.167143   \n",
       "47522  4-Wheel or All-Wheel Drive     Compact Cars  (FFS,TRBO)  16.528333   \n",
       "\n",
       "       city08  comb08  ...  evMotor cylinders  displ  fuelCost08  fuelType  \\\n",
       "0          19      21  ...      NaN       4.0    2.0        2550   Regular   \n",
       "1           9      11  ...      NaN      12.0    4.9        4900   Regular   \n",
       "2          23      27  ...      NaN       4.0    2.2        2000   Regular   \n",
       "3          10      11  ...      NaN       8.0    5.2        4900   Regular   \n",
       "4          17      19  ...      NaN       4.0    2.2        3550   Premium   \n",
       "...       ...     ...  ...      ...       ...    ...         ...       ...   \n",
       "47518      19      22  ...      NaN       4.0    2.2        2450   Regular   \n",
       "47519      20      23  ...      NaN       4.0    2.2        2350   Regular   \n",
       "47520      18      21  ...      NaN       4.0    2.2        2550   Regular   \n",
       "47521      18      21  ...      NaN       4.0    2.2        2550   Regular   \n",
       "47522      16      18  ...      NaN       4.0    2.2        3750   Premium   \n",
       "\n",
       "      highway08  trans_dscr                 createdOn offset  \\\n",
       "0            25         NaN 2013-01-01 00:00:00-05:00    EST   \n",
       "1            14         NaN 2013-01-01 00:00:00-05:00    EST   \n",
       "2            33         SIL 2013-01-01 00:00:00-05:00    EST   \n",
       "3            12         NaN 2013-01-01 00:00:00-05:00    EST   \n",
       "4            23         NaN 2013-01-01 00:00:00-05:00    EST   \n",
       "...         ...         ...                       ...    ...   \n",
       "47518        26       CLKUP 2013-01-01 00:00:00-05:00    EST   \n",
       "47519        28         NaN 2013-01-01 00:00:00-05:00    EST   \n",
       "47520        24       CLKUP 2013-01-01 00:00:00-05:00    EST   \n",
       "47521        24         NaN 2013-01-01 00:00:00-05:00    EST   \n",
       "47522        21       CLKUP 2013-01-01 00:00:00-05:00    EST   \n",
       "\n",
       "                   str_date  \n",
       "0      Jan 01 00:00:00 2013  \n",
       "1      Jan 01 00:00:00 2013  \n",
       "2      Jan 01 00:00:00 2013  \n",
       "3      Jan 01 00:00:00 2013  \n",
       "4      Jan 01 00:00:00 2013  \n",
       "...                     ...  \n",
       "47518  Jan 01 00:00:00 2013  \n",
       "47519  Jan 01 00:00:00 2013  \n",
       "47520  Jan 01 00:00:00 2013  \n",
       "47521  Jan 01 00:00:00 2013  \n",
       "47522  Jan 01 00:00:00 2013  \n",
       "\n",
       "[47523 rows x 21 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(autos\n",
    " .assign(cylinders=autos.cylinders.fillna(0))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cylinders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47518</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47519</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47520</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47521</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47522</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47523 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cylinders\n",
       "0            4.0\n",
       "1           12.0\n",
       "2            4.0\n",
       "3            8.0\n",
       "4            4.0\n",
       "...          ...\n",
       "47518        4.0\n",
       "47519        4.0\n",
       "47520        4.0\n",
       "47521        4.0\n",
       "47522        4.0\n",
       "\n",
       "[47523 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sklearn pipeline to fill in missing cylinders with 0\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# set output to pandas\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')\n",
    "\n",
    "# create pipeline for cylinders\n",
    "cyl_pipe = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "])\n",
    "\n",
    "# try it out\n",
    "cyl_pipe.fit_transform(autos[['cylinders']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cylinders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7138</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7139</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8143</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8144</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8146</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41693</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41694</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41695</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41696</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cylinders\n",
       "7138         0.0\n",
       "7139         0.0\n",
       "8143         0.0\n",
       "8144         0.0\n",
       "8146         0.0\n",
       "...          ...\n",
       "41693        0.0\n",
       "41694        0.0\n",
       "41695        0.0\n",
       "41696        0.0\n",
       "41697        0.0\n",
       "\n",
       "[801 rows x 1 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see where it fill in missing values\n",
    "(cyl_pipe\n",
    " .fit_transform(autos[['cylinders']])\n",
    " .loc[autos.cylinders.isna()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cyl_imputer__cylinders</th>\n",
       "      <th>displ_imputer__displ</th>\n",
       "      <th>remainder__year</th>\n",
       "      <th>remainder__make</th>\n",
       "      <th>remainder__model</th>\n",
       "      <th>remainder__trany</th>\n",
       "      <th>remainder__drive</th>\n",
       "      <th>remainder__VClass</th>\n",
       "      <th>remainder__eng_dscr</th>\n",
       "      <th>remainder__barrels08</th>\n",
       "      <th>...</th>\n",
       "      <th>remainder__comb08</th>\n",
       "      <th>remainder__range</th>\n",
       "      <th>remainder__evMotor</th>\n",
       "      <th>remainder__fuelCost08</th>\n",
       "      <th>remainder__fuelType</th>\n",
       "      <th>remainder__highway08</th>\n",
       "      <th>remainder__trans_dscr</th>\n",
       "      <th>remainder__createdOn</th>\n",
       "      <th>remainder__offset</th>\n",
       "      <th>remainder__str_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>Alfa Romeo</td>\n",
       "      <td>Spider Veloce 2000</td>\n",
       "      <td>Manual 5-spd</td>\n",
       "      <td>Rear-Wheel Drive</td>\n",
       "      <td>Two Seaters</td>\n",
       "      <td>(FFS)</td>\n",
       "      <td>14.167143</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2550</td>\n",
       "      <td>Regular</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1985</td>\n",
       "      <td>Ferrari</td>\n",
       "      <td>Testarossa</td>\n",
       "      <td>Manual 5-spd</td>\n",
       "      <td>Rear-Wheel Drive</td>\n",
       "      <td>Two Seaters</td>\n",
       "      <td>(GUZZLER)</td>\n",
       "      <td>27.046364</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4900</td>\n",
       "      <td>Regular</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1985</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>Charger</td>\n",
       "      <td>Manual 5-spd</td>\n",
       "      <td>Front-Wheel Drive</td>\n",
       "      <td>Subcompact Cars</td>\n",
       "      <td>(FFS)</td>\n",
       "      <td>11.018889</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>Regular</td>\n",
       "      <td>33</td>\n",
       "      <td>SIL</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1985</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>B150/B250 Wagon 2WD</td>\n",
       "      <td>Automatic 3-spd</td>\n",
       "      <td>Rear-Wheel Drive</td>\n",
       "      <td>Vans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.046364</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4900</td>\n",
       "      <td>Regular</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1993</td>\n",
       "      <td>Subaru</td>\n",
       "      <td>Legacy AWD Turbo</td>\n",
       "      <td>Manual 5-spd</td>\n",
       "      <td>4-Wheel or All-Wheel Drive</td>\n",
       "      <td>Compact Cars</td>\n",
       "      <td>(FFS,TRBO)</td>\n",
       "      <td>15.658421</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3550</td>\n",
       "      <td>Premium</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47518</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1993</td>\n",
       "      <td>Subaru</td>\n",
       "      <td>Legacy</td>\n",
       "      <td>Automatic 4-spd</td>\n",
       "      <td>Front-Wheel Drive</td>\n",
       "      <td>Compact Cars</td>\n",
       "      <td>(FFS)</td>\n",
       "      <td>13.523182</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2450</td>\n",
       "      <td>Regular</td>\n",
       "      <td>26</td>\n",
       "      <td>CLKUP</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47519</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1993</td>\n",
       "      <td>Subaru</td>\n",
       "      <td>Legacy</td>\n",
       "      <td>Manual 5-spd</td>\n",
       "      <td>Front-Wheel Drive</td>\n",
       "      <td>Compact Cars</td>\n",
       "      <td>(FFS)</td>\n",
       "      <td>12.935217</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2350</td>\n",
       "      <td>Regular</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47520</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1993</td>\n",
       "      <td>Subaru</td>\n",
       "      <td>Legacy AWD</td>\n",
       "      <td>Automatic 4-spd</td>\n",
       "      <td>4-Wheel or All-Wheel Drive</td>\n",
       "      <td>Compact Cars</td>\n",
       "      <td>(FFS)</td>\n",
       "      <td>14.167143</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2550</td>\n",
       "      <td>Regular</td>\n",
       "      <td>24</td>\n",
       "      <td>CLKUP</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47521</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1993</td>\n",
       "      <td>Subaru</td>\n",
       "      <td>Legacy AWD</td>\n",
       "      <td>Manual 5-spd</td>\n",
       "      <td>4-Wheel or All-Wheel Drive</td>\n",
       "      <td>Compact Cars</td>\n",
       "      <td>(FFS)</td>\n",
       "      <td>14.167143</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2550</td>\n",
       "      <td>Regular</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47522</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1993</td>\n",
       "      <td>Subaru</td>\n",
       "      <td>Legacy AWD Turbo</td>\n",
       "      <td>Automatic 4-spd</td>\n",
       "      <td>4-Wheel or All-Wheel Drive</td>\n",
       "      <td>Compact Cars</td>\n",
       "      <td>(FFS,TRBO)</td>\n",
       "      <td>16.528333</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3750</td>\n",
       "      <td>Premium</td>\n",
       "      <td>21</td>\n",
       "      <td>CLKUP</td>\n",
       "      <td>2013-01-01 00:00:00-05:00</td>\n",
       "      <td>EST</td>\n",
       "      <td>Jan 01 00:00:00 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47523 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cyl_imputer__cylinders  displ_imputer__displ  remainder__year  \\\n",
       "0                         4.0                   2.0             1985   \n",
       "1                        12.0                   4.9             1985   \n",
       "2                         4.0                   2.2             1985   \n",
       "3                         8.0                   5.2             1985   \n",
       "4                         4.0                   2.2             1993   \n",
       "...                       ...                   ...              ...   \n",
       "47518                     4.0                   2.2             1993   \n",
       "47519                     4.0                   2.2             1993   \n",
       "47520                     4.0                   2.2             1993   \n",
       "47521                     4.0                   2.2             1993   \n",
       "47522                     4.0                   2.2             1993   \n",
       "\n",
       "      remainder__make     remainder__model remainder__trany  \\\n",
       "0          Alfa Romeo   Spider Veloce 2000     Manual 5-spd   \n",
       "1             Ferrari           Testarossa     Manual 5-spd   \n",
       "2               Dodge              Charger     Manual 5-spd   \n",
       "3               Dodge  B150/B250 Wagon 2WD  Automatic 3-spd   \n",
       "4              Subaru     Legacy AWD Turbo     Manual 5-spd   \n",
       "...               ...                  ...              ...   \n",
       "47518          Subaru               Legacy  Automatic 4-spd   \n",
       "47519          Subaru               Legacy     Manual 5-spd   \n",
       "47520          Subaru           Legacy AWD  Automatic 4-spd   \n",
       "47521          Subaru           Legacy AWD     Manual 5-spd   \n",
       "47522          Subaru     Legacy AWD Turbo  Automatic 4-spd   \n",
       "\n",
       "                 remainder__drive remainder__VClass remainder__eng_dscr  \\\n",
       "0                Rear-Wheel Drive       Two Seaters               (FFS)   \n",
       "1                Rear-Wheel Drive       Two Seaters           (GUZZLER)   \n",
       "2               Front-Wheel Drive   Subcompact Cars               (FFS)   \n",
       "3                Rear-Wheel Drive              Vans                 NaN   \n",
       "4      4-Wheel or All-Wheel Drive      Compact Cars          (FFS,TRBO)   \n",
       "...                           ...               ...                 ...   \n",
       "47518           Front-Wheel Drive      Compact Cars               (FFS)   \n",
       "47519           Front-Wheel Drive      Compact Cars               (FFS)   \n",
       "47520  4-Wheel or All-Wheel Drive      Compact Cars               (FFS)   \n",
       "47521  4-Wheel or All-Wheel Drive      Compact Cars               (FFS)   \n",
       "47522  4-Wheel or All-Wheel Drive      Compact Cars          (FFS,TRBO)   \n",
       "\n",
       "       remainder__barrels08  ...  remainder__comb08  remainder__range  \\\n",
       "0                 14.167143  ...                 21                 0   \n",
       "1                 27.046364  ...                 11                 0   \n",
       "2                 11.018889  ...                 27                 0   \n",
       "3                 27.046364  ...                 11                 0   \n",
       "4                 15.658421  ...                 19                 0   \n",
       "...                     ...  ...                ...               ...   \n",
       "47518             13.523182  ...                 22                 0   \n",
       "47519             12.935217  ...                 23                 0   \n",
       "47520             14.167143  ...                 21                 0   \n",
       "47521             14.167143  ...                 21                 0   \n",
       "47522             16.528333  ...                 18                 0   \n",
       "\n",
       "       remainder__evMotor remainder__fuelCost08  remainder__fuelType  \\\n",
       "0                     NaN                  2550              Regular   \n",
       "1                     NaN                  4900              Regular   \n",
       "2                     NaN                  2000              Regular   \n",
       "3                     NaN                  4900              Regular   \n",
       "4                     NaN                  3550              Premium   \n",
       "...                   ...                   ...                  ...   \n",
       "47518                 NaN                  2450              Regular   \n",
       "47519                 NaN                  2350              Regular   \n",
       "47520                 NaN                  2550              Regular   \n",
       "47521                 NaN                  2550              Regular   \n",
       "47522                 NaN                  3750              Premium   \n",
       "\n",
       "      remainder__highway08  remainder__trans_dscr      remainder__createdOn  \\\n",
       "0                       25                    NaN 2013-01-01 00:00:00-05:00   \n",
       "1                       14                    NaN 2013-01-01 00:00:00-05:00   \n",
       "2                       33                    SIL 2013-01-01 00:00:00-05:00   \n",
       "3                       12                    NaN 2013-01-01 00:00:00-05:00   \n",
       "4                       23                    NaN 2013-01-01 00:00:00-05:00   \n",
       "...                    ...                    ...                       ...   \n",
       "47518                   26                  CLKUP 2013-01-01 00:00:00-05:00   \n",
       "47519                   28                    NaN 2013-01-01 00:00:00-05:00   \n",
       "47520                   24                  CLKUP 2013-01-01 00:00:00-05:00   \n",
       "47521                   24                    NaN 2013-01-01 00:00:00-05:00   \n",
       "47522                   21                  CLKUP 2013-01-01 00:00:00-05:00   \n",
       "\n",
       "      remainder__offset   remainder__str_date  \n",
       "0                   EST  Jan 01 00:00:00 2013  \n",
       "1                   EST  Jan 01 00:00:00 2013  \n",
       "2                   EST  Jan 01 00:00:00 2013  \n",
       "3                   EST  Jan 01 00:00:00 2013  \n",
       "4                   EST  Jan 01 00:00:00 2013  \n",
       "...                 ...                   ...  \n",
       "47518               EST  Jan 01 00:00:00 2013  \n",
       "47519               EST  Jan 01 00:00:00 2013  \n",
       "47520               EST  Jan 01 00:00:00 2013  \n",
       "47521               EST  Jan 01 00:00:00 2013  \n",
       "47522               EST  Jan 01 00:00:00 2013  \n",
       "\n",
       "[47523 rows x 21 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create more realistic pipeline\n",
    "# set missing cylinders to 0 and displ to median\n",
    "from sklearn.compose import ColumnTransformer\n",
    "cylinders_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "displ_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cyl_imputer', cylinders_imputer, ['cylinders']),\n",
    "        ('displ_imputer', displ_imputer, ['displ'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# Fit and transform the data\n",
    "pipeline.fit_transform(autos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning\n",
    "\n",
    "*Binning* is a process of transforming continuous numerical variables into discrete categorical 'bins'. Binning is used for:\n",
    "\n",
    "- Converting a continuous feature to a categorical feature\n",
    "- Helping with non-linear relationships\n",
    "- Reducing the effects of noise and outliers\n",
    "- Handling missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of city08\n",
    "\n",
    "autos.city08.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a probability plot to see if it is normally distributed\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "stats.probplot(autos.city08, plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(autos.query('city08 < 40').city08, plot=plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin the city08 data with pandas\n",
    "pd.cut(autos.city08, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.cut(autos.city08, bins=10)\n",
    " .value_counts()\n",
    " .sort_index()\n",
    " .plot.bar()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually create edges for bins\n",
    "(pd.cut(autos.city08, bins=[5,10,15,20,40, 140])\n",
    " .value_counts()\n",
    " .sort_index()\n",
    " .plot.bar()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning with sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# Define the binning strategy\n",
    "binning_strategy = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('binning', binning_strategy, ['city08'])\n",
    "    ],\n",
    "    remainder='passthrough'  # This ensures other columns are left unchanged\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[('transformer', column_transformer)])\n",
    "pipeline.fit_transform(autos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit_transform(autos).binning__city08.value_counts().sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline\n",
    "cylinders_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "displ_imputer = SimpleImputer(strategy='median')\n",
    "binning_strategy = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cyl_imputer', cylinders_imputer, ['cylinders']),\n",
    "        ('displ_imputer', displ_imputer, ['displ']),\n",
    "        ('binning', binning_strategy, ['city08'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# Fit and transform the data\n",
    "pipeline.fit_transform(autos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace pyarrow numbers with numpy numbers\n",
    "cylinders_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "displ_imputer = SimpleImputer(strategy='median')\n",
    "binning_strategy = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cyl_imputer', cylinders_imputer, ['cylinders']),\n",
    "        ('displ_imputer', displ_imputer, ['displ']),\n",
    "        ('binning', binning_strategy, ['city08'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# Fit and transform the data\n",
    "pipeline.fit_transform(autos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Transform\n",
    "\n",
    "Log transformation is a data transformation method in which it replaces each variable x with a log(x). This is useful when the data is skewed and you are using a model that assumes normality or linearity.\n",
    "\n",
    "It is also common to use log transformation on the target variable y in regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot to show log of city08 vs original\n",
    "import numpy as np\n",
    "(autos\n",
    "    .assign(city08_log=np.log(autos.city08))\n",
    "    .plot.scatter(x='city08_log', y='city08')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos.city08.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot to show log of city08 vs original\n",
    "\n",
    "(autos\n",
    "    .assign(city08_log=np.log(autos.city08))\n",
    "    .city08_log.hist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model with linear regression to predict city08\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create X and y\n",
    "X = autos.drop(columns=['city08', 'highway08', 'comb08']).select_dtypes('number')\n",
    "y = autos.city08\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# create pipeline fill cylinders with 0 and displ with median\n",
    "\n",
    "cylinders_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "displ_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cyl_imputer', cylinders_imputer, ['cylinders']),\n",
    "        ('displ_imputer', displ_imputer, ['displ']),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('lr', LinearRegression())])\n",
    "\n",
    "# fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, pipeline.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try again with log transform of y\n",
    "# create X and y\n",
    "X = X\n",
    "y_log = np.log(autos.city08)\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train_log, y_test_log = train_test_split(X, y_log, random_state=42)\n",
    "\n",
    "# pipeline\n",
    "pipeline_log = Pipeline(steps=[('preprocessor', preprocessor), ('lr', LinearRegression())])\n",
    "\n",
    "# fit the pipeline\n",
    "pipeline_log.fit(X_train, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_log.score(X_test, y_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take exp of predictions and score the mean absolute error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_pred_log = np.exp(pipeline_log.predict(X_test))\n",
    "\n",
    "mean_absolute_error(np.exp(y_test_log), y_pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "\n",
    "*Scaling* is an ambiguous term that generally means one of two things:\n",
    "\n",
    "-  Min-max scaling - Changing the range of a variable to be between 0 and 1 or -1 to 1.\n",
    "-  Standard scaling (Standardization) - Changing the distribution of a variable to have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "We'll show examples of both below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# create X and y\n",
    "X = autos.drop(columns=['city08', 'highway08', 'comb08']).select_dtypes('number')\n",
    "y = autos.city08\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "cylinders_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "displ_imputer = SimpleImputer(strategy='median')\n",
    "std_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cyl_imputer', cylinders_imputer, ['cylinders']),\n",
    "        ('displ_imputer', displ_imputer, ['displ']),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                           ('std_scaler', std_scaler),\n",
    "                           #('minmax_scaler', minmax_scaler), \n",
    "                           ('lr', LinearRegression())])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: Basic Techniques\n",
    "\n",
    "Predicting mileage from *barrels08*.\n",
    "\n",
    "- Make a model to predict *city08* from *barrels08* using linear regression.\n",
    "- What is the score?\n",
    "- Scatter plot *barrel08* vs *city08*\n",
    "- Make a new model transforming *barrels08* based on the results of the scatter plot.\n",
    "- How does the new model perform?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: Basic Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding\n",
    "\n",
    "Many ML algorithms cannot work with categorical data directly. The categories must be converted into numbers. This process is called *encoding*. \n",
    "\n",
    "One of the most common encodings is *one hot encoding*, also called *dummy encoding*. This creates a new column for each category with a 1 or 0 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos.VClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(autos.VClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(autos.VClass, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cardinality - number of unique values in a column\n",
    "# probably don't want to make ~5k model columns\n",
    "(autos\n",
    " .select_dtypes(object) # use 'string[pyarrow]' if using pyarrow types\n",
    " .nunique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cardinality - number of unique values in a column\n",
    "# probably don't want to make ~5k model columns\n",
    "(autos\n",
    " .select_dtypes(object)\n",
    " .nunique()\n",
    " .index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical encoding in pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "X = autos.drop(columns=['city08', 'highway08', 'comb08', 'createdOn', 'offset', 'str_date'])\n",
    "y = autos.city08\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "cylinders_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "displ_imputer = SimpleImputer(strategy='median')\n",
    "std_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "one_hot_encoder = OneHotEncoder(drop='first', max_categories=10)\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cyl_imputer', cylinders_imputer, ['cylinders']),\n",
    "        ('displ_imputer', displ_imputer, ['displ']),\n",
    "\n",
    "        ('one_hot_encoder', one_hot_encoder, ['make', 'model', 'trany', 'drive', \n",
    "            'VClass', 'eng_dscr', 'evMotor', 'fuelType', 'trans_dscr', ],),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                          ('std_scaler', std_scaler),\n",
    "                           #  ('minmax_scaler', minmax_scaler, ['range']),\n",
    "                           ('lr', LinearRegression())])\n",
    "\n",
    "# fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values AND convert Pandas 2 strings to Pandas 1 strings\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "X = autos.drop(columns=['city08', 'highway08', 'comb08', 'createdOn', 'offset', 'str_date'])\n",
    "y = autos.city08\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "cylinders_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "displ_imputer = SimpleImputer(strategy='median')\n",
    "std_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "one_hot_encoder = OneHotEncoder(drop='first', max_categories=10, sparse_output=False)\n",
    "\n",
    "cat_cols =  ['make', 'model', 'trany', 'drive', \n",
    "            'VClass', 'eng_dscr', 'evMotor', 'fuelType', 'trans_dscr', ]\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cyl_imputer', cylinders_imputer, ['cylinders']),\n",
    "        ('displ_imputer', displ_imputer, ['displ']),\n",
    "        ('cat_imputer', cat_imputer, cat_cols),\n",
    "        ('one_hot_encoder', one_hot_encoder, cat_cols),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                          ('std_scaler', std_scaler),\n",
    "                           #  ('minmax_scaler', minmax_scaler, ['range']),\n",
    "                           ('lr', LinearRegression())])\n",
    "\n",
    "# fit the pipeline\n",
    "pipeline.fit(X_train.assign(**X_train.select_dtypes('string[pyarrow]').astype(str)), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug with FunctionTransformer\n",
    "# And figure out that I need a separate pipeline for categorical columns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "X = autos.drop(columns=['city08', 'highway08', 'comb08', 'createdOn', 'offset', 'str_date'])\n",
    "y = autos.city08\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "cylinders_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "displ_imputer = SimpleImputer(strategy='median')\n",
    "std_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "one_hot_encoder = OneHotEncoder(drop='first', max_categories=10, sparse_output=False)\n",
    "\n",
    "def debug_transformer(X, name):\n",
    "    globals()[name] = X\n",
    "    return X\n",
    "\n",
    "cat_cols =  ['make', 'model', 'trany', 'drive', \n",
    "            'VClass', 'eng_dscr', 'evMotor', 'fuelType', 'trans_dscr', ]\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    ('cat_imputer', cat_imputer),\n",
    "    ('one_hot_encoder', one_hot_encoder)\n",
    "])\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cyl_imputer', cylinders_imputer, ['cylinders']),\n",
    "        ('displ_imputer', displ_imputer, ['displ']),\n",
    "        ('cat_pl', cat_pipe, cat_cols),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                           ('debug', FunctionTransformer(debug_transformer, kw_args={'name': 'tmp_X'})),\n",
    "                           ('std_scaler', std_scaler),\n",
    "                           #  ('minmax_scaler', minmax_scaler, ['range']),\n",
    "                           ('lr', LinearRegression())])\n",
    "\n",
    "# fit the pipeline\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tmp_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtmp_X\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tmp_X' is not defined"
     ]
    }
   ],
   "source": [
    "tmp_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with missing categories in test set w/ handle_unknown='ignore'\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "X = autos.drop(columns=['city08', 'highway08', 'comb08', 'createdOn', 'offset', 'str_date'])\n",
    "y = autos.city08\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Add handle_unknown='ignore' to OneHotEncoder\n",
    "# one_hot_encoder = OneHotEncoder(drop='first', max_categories=10, sparse_output=False)\n",
    "cylinders_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "displ_imputer = SimpleImputer(strategy='median')\n",
    "std_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "one_hot_encoder = OneHotEncoder(drop='first', max_categories=10, sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "def debug_transformer(X, name):\n",
    "    globals()[name] = X\n",
    "    return X\n",
    "\n",
    "cat_cols =  ['make', 'model', 'trany', 'drive', \n",
    "            'VClass', 'eng_dscr', 'evMotor', 'fuelType', 'trans_dscr', ]\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    ('cat_imputer', cat_imputer),\n",
    "    ('one_hot_encoder', one_hot_encoder)\n",
    "])\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cyl_imputer', cylinders_imputer, ['cylinders']),\n",
    "        ('displ_imputer', displ_imputer, ['displ']),\n",
    "        ('cat_pl', cat_pipe, cat_cols),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                           ('debug', FunctionTransformer(debug_transformer, kw_args={'name': 'tmp_X'})),\n",
    "                          ('std_scaler', std_scaler),\n",
    "                           #  ('minmax_scaler', minmax_scaler, ['range']),\n",
    "                           ('lr', LinearRegression())])\n",
    "\n",
    "# fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash Encoding\n",
    "\n",
    "*Hash encoding* is a technique that can be used when there are too many categories to encode with one hot encoding. It is similar to one hot encoding, but the categories are hashed into a smaller number of columns.\n",
    "\n",
    "We are going to use the `category_encoders` library to do the encoding. This library has many other encoders that you can explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category_encoders\n",
      "  Downloading category_encoders-2.6.3-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from category_encoders) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from category_encoders) (1.5.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from category_encoders) (1.13.0)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from category_encoders) (0.14.1)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from category_encoders) (2.2.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from category_encoders) (0.5.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=1.0.5->category_encoders) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=1.0.5->category_encoders) (2024.1)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn>=0.20.0->category_encoders) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn>=0.20.0->category_encoders) (3.4.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from statsmodels>=0.9.0->category_encoders) (24.0)\n",
      "Downloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: category_encoders\n",
      "Successfully installed category_encoders-2.6.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(autos\n",
    " .select_dtypes(object)\n",
    " .nunique()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(autos\n",
    " .select_dtypes(object)\n",
    " .nunique()\n",
    " .pipe(lambda s: s[s > 40])\n",
    " .index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_cardinality_cols = ['make', 'model', 'eng_dscr', 'evMotor', 'trans_dscr']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low cardinality columns\n",
    "(autos\n",
    " .select_dtypes(object)\n",
    " .nunique()\n",
    " .index\n",
    " .difference(high_cardinality_cols)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_cardinality_cols = ['VClass', 'drive', 'fuelType', 'trany']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace one hot encoder with hashing encoder for high cardinality columns\n",
    "from category_encoders import hashing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "X = autos.drop(columns=['city08', 'highway08', 'comb08', 'createdOn', 'offset', 'str_date'])\n",
    "y = autos.city08\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# add hashing encoder\n",
    "cylinders_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "displ_imputer = SimpleImputer(strategy='median')\n",
    "std_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "one_hot_encoder = OneHotEncoder(drop='first', max_categories=10, sparse_output=False, handle_unknown='ignore')\n",
    "hashing_encoder = hashing.HashingEncoder(n_components=10, drop_invariant=True)\n",
    "\n",
    "def debug_transformer(X, name):\n",
    "    globals()[name] = X\n",
    "    return X\n",
    "\n",
    "cat_cols =  ['make', 'model', 'trany', 'drive', \n",
    "            'VClass', 'eng_dscr', 'evMotor', 'fuelType', 'trans_dscr', ]\n",
    "low_cardinality_cols = ['VClass', 'drive', 'fuelType', 'trany']\n",
    "high_cardinality_cols = ['make', 'model', 'eng_dscr', 'evMotor', 'trans_dscr']\n",
    "\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cyl_imputer', cylinders_imputer, ['cylinders']),\n",
    "        ('displ_imputer', displ_imputer, ['displ']),\n",
    "        #('cat_pl', cat_pipe, cat_cols),\n",
    "        ('one_hot_encoder', one_hot_encoder, low_cardinality_cols),\n",
    "        ('hashing_encoder', hashing_encoder, high_cardinality_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                           ('debug', FunctionTransformer(debug_transformer, kw_args={'name': 'tmp_X'})),\n",
    "                          ('std_scaler', std_scaler),\n",
    "                           #  ('minmax_scaler', minmax_scaler, ['range']),\n",
    "                           ('lr', LinearRegression())])\n",
    "\n",
    "# fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Encoding\n",
    "\n",
    "From docstring: [In Target Encoding] Each category is encoded based on a shrunk estimate of the average target\n",
    "values for observations belonging to the category. The encoding scheme mixes\n",
    "the global target mean with the target mean conditioned on the value of the\n",
    "category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import TargetEncoder\n",
    "\n",
    "te = TargetEncoder(target_type='continuous', random_state=42)\n",
    "te.fit_transform(X_train[['make']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace hashing encoder with target encoder for high cardinality columns\n",
    "from category_encoders import hashing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, MinMaxScaler, OneHotEncoder, TargetEncoder\n",
    "\n",
    "# create X and y\n",
    "X = autos.drop(columns=['city08', 'highway08', 'comb08', 'createdOn', 'offset', 'str_date'])\n",
    "y = autos.city08\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# create pipeline fill cylinders with 0 and displ with median\n",
    "cylinders_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "displ_imputer = SimpleImputer(strategy='median')\n",
    "std_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "one_hot_encoder = OneHotEncoder(drop='first', max_categories=10, sparse_output=False, handle_unknown='ignore')\n",
    "hashing_encoder = hashing.HashingEncoder(n_components=10, drop_invariant=True)\n",
    "target_encoder = TargetEncoder(target_type='continuous', random_state=42)\n",
    "\n",
    "def debug_transformer(X, name):\n",
    "    globals()[name] = X\n",
    "    return X\n",
    "\n",
    "cat_cols =  ['make', 'model', 'trany', 'drive', \n",
    "            'VClass', 'eng_dscr', 'evMotor', 'fuelType', 'trans_dscr', ]\n",
    "low_cardinality_cols = ['VClass', 'drive', 'fuelType', 'trany']\n",
    "high_cardinality_cols = ['make', 'model', 'eng_dscr', 'evMotor', 'trans_dscr']\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cyl_imputer', cylinders_imputer, ['cylinders']),\n",
    "        ('displ_imputer', displ_imputer, ['displ']),\n",
    "        ('one_hot_encoder', one_hot_encoder, low_cardinality_cols),\n",
    "        #('hashing_encoder', hashing_encoder, high_cardinality_cols)\n",
    "        ('target_encoder', target_encoder, high_cardinality_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                           ('debug', FunctionTransformer(debug_transformer, kw_args={'name': 'tmp_X'})),\n",
    "                          ('std_scaler', std_scaler),\n",
    "                           #  ('minmax_scaler', minmax_scaler, ['range']),\n",
    "                           ('lr', LinearRegression())])\n",
    "\n",
    "# fit the pipeline\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = autos[['barrels08']]\n",
    "y = autos['city08']\n",
    "\n",
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "pipeline = Pipeline(steps=[('lr', LinearRegression())])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_test.assign(**X_test.select_dtypes('string[pyarrow]').astype(str)),\n",
    "                y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a custom class transformer to remove PyArrow strings (if using PyArrow)\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class PyArrowStringConverter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.assign(**X.select_dtypes('string[pyarrow]').astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace hashing encoder with target encoder for high cardinality columns\n",
    "\n",
    "from category_encoders import hashing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, MinMaxScaler, OneHotEncoder, TargetEncoder\n",
    "\n",
    "\n",
    "# create X and y\n",
    "X = autos.drop(columns=['city08', 'highway08', 'comb08', 'createdOn', 'offset', 'str_date'])\n",
    "y = autos.city08\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# create pipeline fill cylinders with 0 and displ with median\n",
    "\n",
    "cylinders_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "displ_imputer = SimpleImputer(strategy='median')\n",
    "std_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "one_hot_encoder = OneHotEncoder(drop='first', max_categories=10, sparse_output=False, handle_unknown='ignore')\n",
    "hashing_encoder = hashing.HashingEncoder(n_components=10, drop_invariant=True)\n",
    "target_encoder = TargetEncoder(target_type='continuous', random_state=42)\n",
    "\n",
    "def debug_transformer(X, name):\n",
    "    globals()[name] = X\n",
    "    return X\n",
    "\n",
    "cat_cols =  ['make', 'model', 'trany', 'drive', \n",
    "            'VClass', 'eng_dscr', 'evMotor', 'fuelType', 'trans_dscr', ]\n",
    "low_cardinality_cols = ['VClass', 'drive', 'fuelType', 'trany']\n",
    "high_cardinality_cols = ['make', 'model', 'eng_dscr', 'evMotor', 'trans_dscr']\n",
    "\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cyl_imputer', cylinders_imputer, ['cylinders']),\n",
    "        ('displ_imputer', displ_imputer, ['displ']),\n",
    "        ('one_hot_encoder', one_hot_encoder, low_cardinality_cols),\n",
    "        #('hashing_encoder', hashing_encoder, high_cardinality_cols)\n",
    "        ('target_encoder', target_encoder, high_cardinality_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('string_converter', PyArrowStringConverter()),\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('debug', FunctionTransformer(debug_transformer, kw_args={'name': 'tmp_X'})),\n",
    "    ('std_scaler', std_scaler),\n",
    "    #  ('minmax_scaler', minmax_scaler, ['range']),\n",
    "    ('lr', LinearRegression())])\n",
    "\n",
    "# fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Challenge\n",
    "\n",
    "Create a model to predict mileage using only the categorical columns (dropping the *model* column)\n",
    "\n",
    "```\n",
    "cat_cols = ['trany', 'drive', 'VClass', 'eng_dscr', 'evMotor', 'fuelType', 'trans_dscr']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: Categorical Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction    \n",
    "\n",
    "Feature extraction is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "*Principal Component Analysis* (PCA) is a technique for reducing the dimensionality of data. It can also remove noise and might be useful as feature engineering for other algorithms. See my ML algorigthms course for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PCA Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# replace hashing encoder with target encoder for high cardinality columns\n",
    "# import pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from category_encoders import hashing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, MinMaxScaler, OneHotEncoder, TargetEncoder\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')\n",
    "\n",
    "# create X and y\n",
    "X = autos.drop(columns=['city08', 'highway08', 'comb08', 'createdOn', 'offset', 'str_date'])\n",
    "y = autos.city08\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# create pipeline fill cylinders with 0 and displ with median\n",
    "\n",
    "cylinders_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "displ_imputer = SimpleImputer(strategy='median')\n",
    "std_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "one_hot_encoder = OneHotEncoder(drop='first', max_categories=10, sparse_output=False, handle_unknown='ignore')\n",
    "hashing_encoder = hashing.HashingEncoder(n_components=10, drop_invariant=True)\n",
    "target_encoder = TargetEncoder(target_type='continuous', random_state=42)\n",
    "\n",
    "def debug_transformer(X, name):\n",
    "    globals()[name] = X\n",
    "    return X\n",
    "\n",
    "class PyArrowStringConverter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.assign(**X.select_dtypes('string[pyarrow]').astype(str))\n",
    "\n",
    "cat_cols =  ['make', 'model', 'trany', 'drive', \n",
    "            'VClass', 'eng_dscr', 'evMotor', 'fuelType', 'trans_dscr', ]\n",
    "low_cardinality_cols = ['VClass', 'drive', 'fuelType', 'trany']\n",
    "high_cardinality_cols = ['make', 'model', 'eng_dscr', 'evMotor', 'trans_dscr']\n",
    "\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cyl_imputer', cylinders_imputer, ['cylinders']),\n",
    "        ('displ_imputer', displ_imputer, ['displ']),\n",
    "        ('one_hot_encoder', one_hot_encoder, low_cardinality_cols),\n",
    "        #('hashing_encoder', hashing_encoder, high_cardinality_cols)\n",
    "        ('target_encoder', target_encoder, high_cardinality_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('string_converter', PyArrowStringConverter()),\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('std_scaler', std_scaler),\n",
    "    ('pca', PCA(n_components=10)),\n",
    "    ('debug', FunctionTransformer(debug_transformer, kw_args={'name': 'tmp_X'})),    \n",
    "    #  ('minmax_scaler', minmax_scaler, ['range']),\n",
    "    ('lr', LinearRegression())])\n",
    "\n",
    "# fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pros - Noise removed, less columns\n",
    "# Cons - Less explainable\n",
    "tmp_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Aggregation\n",
    "\n",
    "Use grouping to create new features. For example, we can group by manufacturer and then calculate the average fuel economy for each manufacturer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transformer to add mean and std for y for a given column in X\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class AddMeanStd(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col, missing_mean_val, missing_std_val):\n",
    "        self.col = col\n",
    "        # attribute names must be the same as the constructor args\n",
    "        self.missing_mean_val = missing_mean_val\n",
    "        self.missing_std_val = missing_std_val\n",
    "        # track values for each group in col\n",
    "        self.means = {}\n",
    "        self.stds = {}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        assert y.name not in X.columns\n",
    "        with_y = X.assign(y=y)\n",
    "        self.means = with_y.groupby(self.col)['y'].mean().to_dict()\n",
    "        self.stds = with_y.groupby(self.col)['y'].std().to_dict()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # add mean and std for each row\n",
    "        return X.assign(**{\n",
    "            f'{self.col}_mean': X[self.col].map(self.means).fillna(self.missing_mean_val),\n",
    "            f'{self.col}_std': X[self.col].map(self.stds).fillna(self.missing_std_val)\n",
    "        })\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline wtih Aggregation\n",
    "from sklearn.decomposition import PCA\n",
    "# replace hashing encoder with target encoder for high cardinality columns\n",
    "\n",
    "from category_encoders import hashing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, MinMaxScaler, OneHotEncoder, TargetEncoder\n",
    "\n",
    "\n",
    "# create X and y\n",
    "X = autos.drop(columns=['city08', 'highway08', 'comb08', 'createdOn', 'offset', 'str_date'])\n",
    "y = autos.city08\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# create pipeline fill cylinders with 0 and displ with median\n",
    "\n",
    "cylinders_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "displ_imputer = SimpleImputer(strategy='median')\n",
    "std_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "one_hot_encoder = OneHotEncoder(drop='first', max_categories=10, sparse_output=False, handle_unknown='ignore')\n",
    "hashing_encoder = hashing.HashingEncoder(n_components=10, drop_invariant=True)\n",
    "target_encoder = TargetEncoder(target_type='continuous', random_state=42)\n",
    "\n",
    "def debug_transformer(X, name):\n",
    "    globals()[name] = X\n",
    "    return X\n",
    "\n",
    "cat_cols =  ['make', 'model', 'trany', 'drive', \n",
    "            'VClass', 'eng_dscr', 'evMotor', 'fuelType', 'trans_dscr', ]\n",
    "low_cardinality_cols = ['VClass', 'drive', 'fuelType', 'trany']\n",
    "high_cardinality_cols = ['make', 'model', 'eng_dscr', 'evMotor', 'trans_dscr']\n",
    "\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cyl_imputer', cylinders_imputer, ['cylinders']),\n",
    "        ('displ_imputer', displ_imputer, ['displ']),\n",
    "        ('one_hot_encoder', one_hot_encoder, low_cardinality_cols),\n",
    "        #('hashing_encoder', hashing_encoder, high_cardinality_cols)\n",
    "        ('target_encoder', target_encoder, high_cardinality_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('string_converter', PyArrowStringConverter()),\n",
    "    ('make_mean_std', AddMeanStd(col='make', missing_mean_val=0, missing_std_val=0)),\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('std_scaler', std_scaler),\n",
    "    #('pca', PCA(n_components=10)),\n",
    "    ('debug', FunctionTransformer(debug_transformer, kw_args={'name': 'tmp_X'})),    \n",
    "    #  ('minmax_scaler', minmax_scaler, ['range']),\n",
    "    ('lr', LinearRegression())])\n",
    "\n",
    "# fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF\n",
    "\n",
    "*Term frequency–inverse document frequency* (TFIDF) is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a feature for text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def combine_str_cols_transformer(X, cols, new_col_name):\n",
    "    # tdidf expects a single column of strings\n",
    "    return X.assign(**{new_col_name: X[cols].fillna('').agg(' '.join, axis='columns')})[new_col_name]\n",
    "\n",
    "text_pipeline = Pipeline([\n",
    "    ('combine_str', FunctionTransformer(combine_str_cols_transformer, \n",
    "                                        kw_args={'cols': cat_cols, 'new_col_name': 'all_str'})),\n",
    "    ('tfidf', TfidfVectorizer()), # can't be sparse because of Pandas\n",
    "    ('combine_debug', FunctionTransformer(debug_transformer, kw_args={'name': 'tmp_combine'})),\n",
    "    ('make_dense', FunctionTransformer(lambda X: X.toarray())),\n",
    "    ('pca', PCA(n_components=10)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline.fit_transform(autos[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_combine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add TFIDF to combination of string columns\n",
    "from sklearn.decomposition import PCA\n",
    "# replace hashing encoder with target encoder for high cardinality columns\n",
    "\n",
    "from category_encoders import hashing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, MinMaxScaler, OneHotEncoder, TargetEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# import pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "# create X and y\n",
    "X = autos.drop(columns=['city08', 'highway08', 'comb08', 'createdOn', 'offset', 'str_date'])\n",
    "y = autos.city08\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# create pipeline fill cylinders with 0 and displ with median\n",
    "\n",
    "cylinders_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "displ_imputer = SimpleImputer(strategy='median')\n",
    "std_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "one_hot_encoder = OneHotEncoder(drop='first', max_categories=10, sparse_output=False, handle_unknown='ignore')\n",
    "hashing_encoder = hashing.HashingEncoder(n_components=10, drop_invariant=True)\n",
    "target_encoder = TargetEncoder(target_type='continuous', random_state=42)\n",
    "\n",
    "def debug_transformer(X, name):\n",
    "    globals()[name] = X\n",
    "    return X\n",
    "\n",
    "def combine_str_cols_transformer(X, cols, new_col_name):\n",
    "    # tdidf expects a single column of strings\n",
    "    return X.assign(**{new_col_name: X[cols].fillna('').agg(' '.join, axis='columns')})[new_col_name]\n",
    "\n",
    "cat_cols =  ['make', 'model', 'trany', 'drive', \n",
    "            'VClass', 'eng_dscr', 'evMotor', 'fuelType', 'trans_dscr', ]\n",
    "low_cardinality_cols = ['VClass', 'drive', 'fuelType', 'trany']\n",
    "high_cardinality_cols = ['make', 'model', 'eng_dscr', 'evMotor', 'trans_dscr']\n",
    "\n",
    "\n",
    "text_pipeline = Pipeline([\n",
    "    ('combine_str', FunctionTransformer(combine_str_cols_transformer, \n",
    "                                        kw_args={'cols': cat_cols, 'new_col_name': 'all_str'})),\n",
    "    ('tfidf', TfidfVectorizer()), # can't be sparse because of Pandas\n",
    "    ('combine_debug', FunctionTransformer(debug_transformer, kw_args={'name': 'tmp_combine'})),\n",
    "    ('make_dense', FunctionTransformer(lambda X: X.toarray())),\n",
    "    ('pca', PCA(n_components=10)),\n",
    "])\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cyl_imputer', cylinders_imputer, ['cylinders']),\n",
    "        ('displ_imputer', displ_imputer, ['displ']),\n",
    "        ('one_hot_encoder', one_hot_encoder, low_cardinality_cols),\n",
    "        #('hashing_encoder', hashing_encoder, high_cardinality_cols)\n",
    "        ('target_encoder', target_encoder, high_cardinality_cols),\n",
    "        ('text', text_pipeline, cat_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('string_converter', PyArrowStringConverter()),\n",
    "    ('make_mean_std', AddMeanStd(col='make', missing_mean_val=0, missing_std_val=0)),\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('std_scaler', std_scaler),\n",
    "    #('pca', PCA(n_components=10)),\n",
    "    ('debug', FunctionTransformer(debug_transformer, kw_args={'name': 'tmp_X'})),    \n",
    "    #  ('minmax_scaler', minmax_scaler, ['range']),\n",
    "    ('lr', LinearRegression())])\n",
    "\n",
    "# fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text pipeline to sklearn transformer so we can keep in pandas\n",
    "# and preserve index\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "def combine_str_cols_transformer(X, cols, new_col_name):\n",
    "    # tdidf expects a single column of strings\n",
    "    return X.assign(**{new_col_name: X[cols].fillna('').agg(' '.join, axis='columns')})[new_col_name]\n",
    "\n",
    "\n",
    "class TextPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cat_cols):\n",
    "        self.cat_cols = cat_cols\n",
    "        self.text_pipeline = Pipeline([\n",
    "            ('combine_str', FunctionTransformer(combine_str_cols_transformer, \n",
    "                                                kw_args={'cols': cat_cols, 'new_col_name': 'all_str'})),\n",
    "            ('tfidf', TfidfVectorizer()), # can't be sparse because of Pandas\n",
    "            ('make_dense', FunctionTransformer(lambda X: X.toarray())),\n",
    "            ('pca', PCA(n_components=10)),\n",
    "        ])\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.text_pipeline.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        res = self.text_pipeline.transform(X)\n",
    "        # replace index with X index\n",
    "        df = (res\n",
    "              .assign(index=X.index)\n",
    "              .set_index('index')\n",
    "        )\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the pipeline\n",
    "text_pipeline = TextPipeline(cat_cols)\n",
    "text_pipeline.fit(X_train, y_train)\n",
    "text_pipeline.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add TFIDF to combination of string columns\n",
    "from sklearn.decomposition import PCA\n",
    "# replace hashing encoder with target encoder for high cardinality columns\n",
    "\n",
    "from category_encoders import hashing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, MinMaxScaler, OneHotEncoder, TargetEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# create X and y\n",
    "X = autos.drop(columns=['city08', 'highway08', 'comb08', 'createdOn', 'offset', 'str_date'])\n",
    "y = autos.city08\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# create pipeline fill cylinders with 0 and displ with median\n",
    "\n",
    "cylinders_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "displ_imputer = SimpleImputer(strategy='median')\n",
    "std_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "one_hot_encoder = OneHotEncoder(drop='first', max_categories=10, sparse_output=False, handle_unknown='ignore')\n",
    "hashing_encoder = hashing.HashingEncoder(n_components=10, drop_invariant=True)\n",
    "target_encoder = TargetEncoder(target_type='continuous', random_state=42)\n",
    "\n",
    "def debug_transformer(X, name):\n",
    "    globals()[name] = X\n",
    "    return X\n",
    "\n",
    "cat_cols =  ['make', 'model', 'trany', 'drive', \n",
    "            'VClass', 'eng_dscr', 'evMotor', 'fuelType', 'trans_dscr', ]\n",
    "low_cardinality_cols = ['VClass', 'drive', 'fuelType', 'trany']\n",
    "high_cardinality_cols = ['make', 'model', 'eng_dscr', 'evMotor', 'trans_dscr']\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cyl_imputer', cylinders_imputer, ['cylinders']),\n",
    "        ('displ_imputer', displ_imputer, ['displ']),\n",
    "        ('one_hot_encoder', one_hot_encoder, low_cardinality_cols),\n",
    "        #('hashing_encoder', hashing_encoder, high_cardinality_cols)\n",
    "        ('target_encoder', target_encoder, high_cardinality_cols),\n",
    "        ('text', TextPipeline(cat_cols), cat_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('string_converter', PyArrowStringConverter()),\n",
    "    ('make_mean_std', AddMeanStd(col='make', missing_mean_val=0, missing_std_val=0)),\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('debug', FunctionTransformer(debug_transformer, kw_args={'name': 'tmp_X'})),        \n",
    "    ('std_scaler', std_scaler),\n",
    "    #('pca', PCA(n_components=10)),\n",
    "    #  ('minmax_scaler', minmax_scaler, ['range']),\n",
    "    ('lr', LinearRegression())])\n",
    "\n",
    "# fit the pipeline\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Embeddings\n",
    "\n",
    "*Text embeddings* are a type of feature extraction that is used for text data. They are a numerical representation of text that can be used in machine learning algorithms. They are often used as a feature for text classification. A common example is a vector to represent man, woman, and king. When you add the difference between woman and man to king, you get queen.\n",
    "\n",
    "We will use the Spacy library to create text embeddings. Spacy is a library for natural language processing (NLP). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install spacy language model\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class SpacyEmbeddingVectorizer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, columns):\n",
    "        # Load the SpaCy model\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        text = (X[self.columns].fillna('').apply(lambda x: ' '.join(x), axis='columns'))\n",
    "        res = [self.nlp(row).vector for row in text]\n",
    "        df = pd.DataFrame(res, index=X.index)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try it out on cat_cols - takes 4+ minutes on my machine\n",
    "# using sample to speed up\n",
    "\n",
    "embeds = SpacyEmbeddingVectorizer(cat_cols)\n",
    "embeds.fit_transform(X_train.sample(1_000, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add embeddings\n",
    "from sklearn.decomposition import PCA\n",
    "# replace hashing encoder with target encoder for high cardinality columns\n",
    "\n",
    "from category_encoders import hashing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, MinMaxScaler, OneHotEncoder, TargetEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# create X and y\n",
    "X = autos.drop(columns=['city08', 'highway08', 'comb08', 'createdOn', 'offset', 'str_date'])\n",
    "y = autos.city08\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# create pipeline fill cylinders with 0 and displ with median\n",
    "\n",
    "cylinders_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "displ_imputer = SimpleImputer(strategy='median')\n",
    "std_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "one_hot_encoder = OneHotEncoder(drop='first', max_categories=10, sparse_output=False, handle_unknown='ignore')\n",
    "hashing_encoder = hashing.HashingEncoder(n_components=10, drop_invariant=True)\n",
    "target_encoder = TargetEncoder(target_type='continuous', random_state=42)\n",
    "\n",
    "def debug_transformer(X, name):\n",
    "    globals()[name] = X\n",
    "    return X\n",
    "\n",
    "def combine_str_cols_transformer(X, cols, new_col_name):\n",
    "    # tdidf expects a single column of strings\n",
    "    return X.assign(**{new_col_name: X[cols].agg(' '.join, axis='columns')})[new_col_name]\n",
    "\n",
    "cat_cols =  ['make', 'model', 'trany', 'drive', \n",
    "            'VClass', 'eng_dscr', 'evMotor', 'fuelType', 'trans_dscr', ]\n",
    "low_cardinality_cols = ['VClass', 'drive', 'fuelType', 'trany']\n",
    "high_cardinality_cols = ['make', 'model', 'eng_dscr', 'evMotor', 'trans_dscr']\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cyl_imputer', cylinders_imputer, ['cylinders']),\n",
    "        ('displ_imputer', displ_imputer, ['displ']),\n",
    "        ('one_hot_encoder', one_hot_encoder, low_cardinality_cols),\n",
    "        #('hashing_encoder', hashing_encoder, high_cardinality_cols)\n",
    "        ('target_encoder', target_encoder, high_cardinality_cols),\n",
    "        ('text', SpacyEmbeddingVectorizer(cat_cols), cat_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('string_converter', PyArrowStringConverter()),\n",
    "    ('make_mean_std', AddMeanStd(col='make', missing_mean_val=0, missing_std_val=0)),\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('debug', FunctionTransformer(debug_transformer, kw_args={'name': 'tmp_X'})),        \n",
    "    ('std_scaler', std_scaler),\n",
    "    #('pca', PCA(n_components=10)),\n",
    "    #  ('minmax_scaler', minmax_scaler, ['range']),\n",
    "    ('lr', LinearRegression())])\n",
    "\n",
    "# fit the pipeline\n",
    "limit = 1_000\n",
    "pipeline.fit(X_train.iloc[:limit], y_train.iloc[:limit])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: Feature Extraction\n",
    "\n",
    "Create a model that predicts mileage based on the spacy embeddings of the text columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "column_transformers = ColumnTransformer(\n",
    "        transformers=[\n",
    "                ('text', SpacyEmbeddingVectorizer(cat_cols), cat_cols)\n",
    "        ],\n",
    "        remainder='drop' # drop everything else\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "  ('preprocessor', column_transformers),\n",
    "  ('LinearRegression', LinearRegression())\n",
    "])\n",
    "\n",
    "# fit the pipeline\n",
    "limit = 1_000\n",
    "pipeline.fit(X_train.iloc[:limit], y_train.iloc[:limit])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Features\n",
    "\n",
    "Time based data often has trends and seasonality. We can extract features from the date and time to capture these patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Date and Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install feature-engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use feature-engine library to pull out date features\n",
    "\n",
    "from feature_engine.datetime import DatetimeFeatures\n",
    "\n",
    "dtf = DatetimeFeatures(features_to_extract='all')\n",
    "dtf.fit_transform(autos[['createdOn']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonality and Trend\n",
    "\n",
    "We can use the `seasonal_decompose` function from `statsmodels`` to decompose a time series into its components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "seasonal_decompose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ford = (autos\n",
    "        .query(\"make == 'Ford'\")\n",
    "        #.groupby(pd.Grouper(key='createdOn', freq='ME'))\n",
    "        .groupby('year')\n",
    "        .city08\n",
    "        .median()\n",
    "        .ffill())\n",
    "ford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of 5 year decomposition (period=5 on yearly data)\n",
    "from matplotlib import pyplot as plt\n",
    "decomposition = seasonal_decompose(ford, model='additive', period=5)\n",
    "\n",
    "# Plot the decomposition\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(15, 8))\n",
    "ford.plot(ax=ax1, title='Original')\n",
    "decomposition.trend.plot(ax=ax2, title='Trend')\n",
    "decomposition.seasonal.plot(ax=ax3, title='Seasonality')\n",
    "decomposition.resid.plot(ax=ax4, title='Residuals')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "def get_seasonal(group, time_col, agg_col, period=1):\n",
    "    # Sort by date and set index\n",
    "    group = group.sort_values(time_col)\n",
    "    # rename index to index\n",
    "    group.index.name = 'index'\n",
    "    ts = group.set_index(time_col)[agg_col]\n",
    "\n",
    "    # Handle groups with insufficient data\n",
    "    if len(ts) < 2:\n",
    "        return group.assign(seasonal=0, trend=0, resid=0)\n",
    "\n",
    "    # Decompose the time series\n",
    "    res = seasonal_decompose(ts, model='additive', period=period, extrapolate_trend='freq')\n",
    "\n",
    "    # Reassign the decomposed components to the group\n",
    "    return (group\n",
    "            .assign(seasonal=res.seasonal.values,\n",
    "                    trend=res.trend.values,\n",
    "                    resid=res.resid.values))\n",
    "\n",
    "def add_seasonal(df, time_col, group_cols, agg_col):\n",
    "    all_group_cols = [time_col] + group_cols\n",
    "    return (df\n",
    "            .groupby(group_cols)\n",
    "            .apply(get_seasonal, time_col=time_col, agg_col=agg_col, period=1)\n",
    "            .drop(columns=group_cols)\n",
    "            .reset_index(drop=False)\n",
    "            .set_index('index')\n",
    "            .loc[df.index]\n",
    "    )\n",
    "\n",
    "\n",
    "# Example usage\n",
    "res = add_seasonal(X, 'year', ['make'], agg_col='barrels08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.iloc[:, -5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline wtih Aggregation\n",
    "from sklearn.decomposition import PCA\n",
    "# replace hashing encoder with target encoder for high cardinality columns\n",
    "\n",
    "from category_encoders import hashing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, MinMaxScaler, OneHotEncoder, TargetEncoder\n",
    "\n",
    "\n",
    "# create X and y\n",
    "X = autos.drop(columns=['city08', 'highway08', 'comb08', 'createdOn', 'offset', 'str_date'])\n",
    "y = autos.city08\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# create pipeline fill cylinders with 0 and displ with median\n",
    "\n",
    "cylinders_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "displ_imputer = SimpleImputer(strategy='median')\n",
    "std_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "one_hot_encoder = OneHotEncoder(drop='first', max_categories=10, sparse_output=False, handle_unknown='ignore')\n",
    "hashing_encoder = hashing.HashingEncoder(n_components=10, drop_invariant=True)\n",
    "target_encoder = TargetEncoder(target_type='continuous', random_state=42)\n",
    "\n",
    "def debug_transformer(X, name):\n",
    "    globals()[name] = X\n",
    "    return X\n",
    "\n",
    "cat_cols =  ['make', 'model', 'trany', 'drive', \n",
    "            'VClass', 'eng_dscr', 'evMotor', 'fuelType', 'trans_dscr', ]\n",
    "low_cardinality_cols = ['VClass', 'drive', 'fuelType', 'trany']\n",
    "high_cardinality_cols = ['make', 'model', 'eng_dscr', 'evMotor', 'trans_dscr']\n",
    "\n",
    "# create the seasonal transformer\n",
    "class SeasonTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, time_col, group_cols, agg_col):\n",
    "        self.time_col = time_col\n",
    "        self.group_cols = group_cols\n",
    "        self.agg_col = agg_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return add_seasonal(X, self.time_col, self.group_cols, self.agg_col)\n",
    "        \n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cyl_imputer', cylinders_imputer, ['cylinders']),\n",
    "        ('displ_imputer', displ_imputer, ['displ']),\n",
    "        ('one_hot_encoder', one_hot_encoder, low_cardinality_cols),\n",
    "        #('hashing_encoder', hashing_encoder, high_cardinality_cols)\n",
    "        ('target_encoder', target_encoder, high_cardinality_cols),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('string_converter', PyArrowStringConverter()),\n",
    "    ('make_mean_std', AddMeanStd(col='make', missing_mean_val=0, missing_std_val=0)),\n",
    "        ('seasonal_decompose', SeasonTransformer(time_col='year', group_cols=['make'], agg_col='barrels08')),\n",
    "#          ['year', 'make', \n",
    "#           'barrels08']),  # need to make sure we pass all columns needed\n",
    "\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('debug', FunctionTransformer(debug_transformer, kw_args={'name': 'tmp_X'})),    \n",
    "    ('std_scaler', std_scaler),\n",
    "    #('pca', PCA(n_components=10)),\n",
    "\n",
    "    #  ('minmax_scaler', minmax_scaler, ['range']),\n",
    "    ('lr', LinearRegression())])\n",
    "\n",
    "# fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model to predict monthly airline passgengers from https://www.transtats.bts.gov/Data_Elements.aspx?Data=1\n",
    "# for some reason this output is not Excel but HTML\n",
    "airlines = pd.read_html('data/Passengers_2024.xls')\n",
    "raw = airlines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweak_airline(df_):\n",
    "  return (df_\n",
    "          .query('Month != \"TOTAL\"')\n",
    "          .astype({'Month': 'int64'})\n",
    "          .assign(date=lambda df: pd.to_datetime(df[['Year', 'Month']].assign(day=1)))\n",
    "  )\n",
    "\n",
    "air = tweak_airline(raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: Temporal Features\n",
    "\n",
    "Using the airline data, create a linear regression model to predict the number of passengers for the next month based on the current month.\n",
    "\n",
    "Then make another model using the `seasonal_decompose` function to add a seasonality component to the model. How do the models compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "*Feature selection* is the process of selecting a subset of features that are most relevant to the target variable. There are many reasons to do this:\n",
    "\n",
    "-  Simplicity - Fewer features are easier to interpret.\n",
    "-  Memory - Fewer features require less memory to store and less computation.\n",
    "-  Speed - Fewer features result in faster algorithms.\n",
    "\n",
    "There are many techniques for feature selection. We will cover a few of them here:\n",
    "\n",
    "-  Feature importance\n",
    "-  Recursive feature elimination\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance and Weights\n",
    "\n",
    "Many models can provide a feature importance or weight for each feature. This is a measure of how much the model depends on that feature. We can use this to select the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline wtih Aggregation\n",
    "from sklearn.decomposition import PCA\n",
    "# replace hashing encoder with target encoder for high cardinality columns\n",
    "\n",
    "from category_encoders import hashing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, MinMaxScaler, OneHotEncoder, TargetEncoder\n",
    "\n",
    "\n",
    "# create X and y\n",
    "X = autos.drop(columns=['city08', 'highway08', 'comb08', 'createdOn', 'offset', 'str_date'])\n",
    "y = autos.city08\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# create pipeline fill cylinders with 0 and displ with median\n",
    "\n",
    "cylinders_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "displ_imputer = SimpleImputer(strategy='median')\n",
    "std_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "one_hot_encoder = OneHotEncoder(drop='first', max_categories=10, sparse_output=False, handle_unknown='ignore')\n",
    "hashing_encoder = hashing.HashingEncoder(n_components=10, drop_invariant=True)\n",
    "target_encoder = TargetEncoder(target_type='continuous', random_state=42)\n",
    "\n",
    "def debug_transformer(X, name):\n",
    "    globals()[name] = X\n",
    "    return X\n",
    "\n",
    "cat_cols =  ['make', 'model', 'trany', 'drive', \n",
    "            'VClass', 'eng_dscr', 'evMotor', 'fuelType', 'trans_dscr', ]\n",
    "low_cardinality_cols = ['VClass', 'drive', 'fuelType', 'trany']\n",
    "high_cardinality_cols = ['make', 'model', 'eng_dscr', 'evMotor', 'trans_dscr']\n",
    "\n",
    "# create the seasonal transformer\n",
    "class SeasonTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, time_col, group_cols, agg_col):\n",
    "        self.time_col = time_col\n",
    "        self.group_cols = group_cols\n",
    "        self.agg_col = agg_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return add_seasonal(X, self.time_col, self.group_cols, self.agg_col)\n",
    "        \n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cyl_imputer', cylinders_imputer, ['cylinders']),\n",
    "        ('displ_imputer', displ_imputer, ['displ']),\n",
    "        ('one_hot_encoder', one_hot_encoder, low_cardinality_cols),\n",
    "        #('hashing_encoder', hashing_encoder, high_cardinality_cols)\n",
    "        ('target_encoder', target_encoder, high_cardinality_cols),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('string_converter', PyArrowStringConverter()),\n",
    "    ('make_mean_std', AddMeanStd(col='make', missing_mean_val=0, missing_std_val=0)),\n",
    "        ('seasonal_decompose', SeasonTransformer(time_col='year', group_cols=['make'], agg_col='barrels08')),\n",
    "#          ['year', 'make', \n",
    "#           'barrels08']),  # need to make sure we pass all columns needed\n",
    "\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('debug', FunctionTransformer(debug_transformer, kw_args={'name': 'tmp_X'})),    \n",
    "    ('std_scaler', std_scaler),\n",
    "    #('pca', PCA(n_components=10)),\n",
    "\n",
    "    #  ('minmax_scaler', minmax_scaler, ['range']),\n",
    "    ('lr', LinearRegression())])\n",
    "\n",
    "# fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get linear regression model\n",
    "\n",
    "lr = pipeline.named_steps['lr']\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(lr.coef_, index=lr.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.Series(lr.coef_, index=lr.feature_names_in_)\n",
    " .sort_values(key=abs)\n",
    " .plot.barh()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lr.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.Series(lr.coef_, index=lr.feature_names_in_)\n",
    " .sort_values(key=abs)\n",
    " .tail(25)\n",
    " .plot.barh()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note scale of x axis\n",
    "(pd.Series(lr.coef_, index=lr.feature_names_in_)\n",
    " .sort_values(key=abs)\n",
    " .head(26)\n",
    " .plot.barh()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use xgboost to make a model and then get feature importances\n",
    "import xgboost as xgb\n",
    "\n",
    "# create X and y\n",
    "X = autos.drop(columns=['city08', 'highway08', 'comb08', 'createdOn', 'offset', 'str_date'])\n",
    "y = autos.city08\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X.assign(**X.select_dtypes(object).astype('category')),\n",
    "    y, random_state=42)\n",
    "\n",
    "xg = xgb.XGBRegressor(enable_categorical=True, random_state=42)\n",
    "xg.fit(X_train, y_train)\n",
    "xg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(xg.feature_importances_, index=X_train.columns).sort_values().tail(25).plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot range vs city mpg\n",
    "(autos\n",
    " .plot.scatter(x='range', y='city08')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(xg.feature_importances_, index=X_train.columns).sort_values().iloc[:-1].plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make xg model with just range, barrels08, fuelType, and cylinders\n",
    "xg_simple = xgb.XGBRegressor(enable_categorical=True, random_state=42)\n",
    "xg_simple.fit(X_train[['range', 'barrels08', 'fuelType', 'cylinders']], y_train)\n",
    "xg_simple.score(X_test[['range', 'barrels08', 'fuelType', 'cylinders']], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination\n",
    "\n",
    "*Recursive feature elimination* (RFE) is a feature selection method that fits a model and removes the weakest feature (or features) until the specified number of features is reached. It is a greedy optimization algorithm that aims to find the best performing feature subset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# use rfe with xgboost\n",
    "xg_model = xgb.XGBRegressor(enable_categorical=True, random_state=42)\n",
    "rfe = RFE(xg_model, n_features_to_select=3)\n",
    "\n",
    "X = autos.drop(columns=['city08', 'highway08', 'comb08', 'createdOn', 'offset', 'str_date'])\n",
    "y = autos.city08\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    #X.assign(**X.select_dtypes('string[pyarrow]').astype('category')),\n",
    "    X.select_dtypes('number'),\n",
    "    y, random_state=42)\n",
    "\n",
    "rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the API to determine which features were selected\n",
    "rfe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'features':X_train.columns,\n",
    "              'support': rfe.support_,\n",
    "              'ranking':rfe.ranking_}).sort_values('ranking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make model with barrels08, range, and fuelCost08\n",
    "xg_simple = xgb.XGBRegressor(enable_categorical=True, random_state=42)\n",
    "xg_simple.fit(X_train[['barrels08', 'range', 'fuelCost08']], y_train)\n",
    "xg_simple.score(X_test[['barrels08', 'range', 'fuelCost08']], y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a Random Column\n",
    "\n",
    "Another technique is to add a column of random numbers. We should be able to drop any columns that perform worse than the random column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and add a random column\n",
    "X = (autos\n",
    "     .drop(columns=['city08', 'highway08', 'comb08', 'createdOn', 'offset', 'str_date'])\n",
    "     .assign(random=lambda df: np.random.random(size=len(df)))\n",
    "     )\n",
    "\n",
    "y = autos.city08\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X.assign(**X.select_dtypes(object).astype('category')),\n",
    "    y, random_state=42)\n",
    "\n",
    "xg = xgb.XGBRegressor(enable_categorical=True, random_state=42)\n",
    "xg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at feature importances\n",
    "# In this case the random column is the least important \n",
    "pd.Series(xg.feature_importances_, index=X_train.columns).sort_values().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: Feature Selection\n",
    "\n",
    "Apply RFE to linear regression model to limit model to 5 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion - Next Steps\n",
    "\n",
    "- Practice! - Watching and listening is not enough. You need to practice what you have learned.\n",
    "- Understand your data - You need to understand your data and the problem you are trying to solve.\n",
    "- Master Pandas and Scikit-Learn - These are the most important tools for feature engineering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
